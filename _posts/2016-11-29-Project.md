---
layout: post
title: Modelling Market Dynamics on Short Timescales
---

Determining the "fair" market price of an asset from order book data and the history of orders and trades. 

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Background


## The Fair Price

To a layman and to most retail investors the price of a financial
asset is quite clear. The price that Google finance reports is the
proper price, and if one wishes to buy or sell they can do so at a price
that's at most within a few cents of this quoted price. 

But to many financial institutions, that few cents actually makes
a big difference. In high frequency trading in particular, one usually
only holds positions for short periods of time - a matter of minutes
- and the magnitude of the price changes in such a time aren't much
  larger than a few cents. Hence in this arena one of the most ubiquitous
  problems is determining a "fair" price of an asset to a high resolution. 

But if we demand that we need the fair price of an asset accurate
to say, half a cent, suddenly it's quite unclear how to get this price.
If a stock is trading at \\$10, what's meant is that the last trade was at \\​$10, which may have been a while ago. But right now, someone is willing to buy at \\$9.99 and someoneis willing to sell at \\​$10.01, and we just take the average of the
two prices to get the fair price. As we soon see, this isn't always
a very good idea. 

A little big of jargon before we continue:

* The _bid_ is the price at which someone is willing to buy the
  asset in question.
* The _offer_ is the price at which someone is willing to sell
  the asset.
* The _midpoint_ is the average of the bid and the offer.
* The _spread_ is the difference between the bid and the offer. 


## The Inverse Weighted Midpoint

The next step after using the midpoint is to realize that a trade
is more likely to occur at the bid if the bid is thin. That is, in
a situation where 100 people want to sell at \\$11 and only one person
wants to buy at \\$9, the next trade is more likely to occur at \\$9.
This is because people generally want to buy things that have high
value and sell things that have low value. If the fair price was \\$10
then one would think that there would be more than just one person
who wants to buy it at \\$9, since you'd make a whole dollar of profit. 

This leads to the _inversed weighted midpoint_ (IWM), where we
take a weighted average of the bid and the offer, but where the bid
is weighted with the offer depth and vice versa. In the case above
the IWM would be \\$9.02, since


\[
\frac{100}{100+1}\times9+\frac{1}{100+1}\times11=9.02
\]


The IWM is a bit more sophisticated than just the midpoint, but there
is still a lot of room for improvement. For one, the IWM only considers
the best bid and offer. In the above example if the next best bid
was \\$8 with only one bidder, then the trade of a single stock would
send the IWM all the way to \\$8. Even more important is the "current"
qualifier: the IWM doesn't depend at all on the history of bids and
offers, or on what trades have occurred even in the recent past, which
affect the next traded price in quite complex ways. 

<div class="imgcap">
<img src="/assets/project/1.png">
<div class="thecap" style="text-align:justify">
The inverse weighted midpoint. Here the grey shaded regions represent the bid and offer depth. Note that the IWM is close to the bid if the bid depth is thin. 
</div>
</div>



## Market Dynamics

Now we realize that's it's almost a platitude to say that the stock
market is unpredictable, but this is usually said in the context of
longer time scales of weeks or months. But since market dynamics at
very short time scales are driven by algorithms, we should expect
to see some definite regularities: 

* The next traded price usually happens at the bid or the ask, and the
  probability of the next trade occurring outside of that range is drastically
  smaller. One exception is when we have a temporary lapse in liquidity,
  where there are so few trades occurring that the price is likely to
  move before the next trade. The other is in a flurry of trades where
  the order book has a hard time keeping up. 
* Whenever someone "crosses the spread", that is, one buys at the
  offer or sells at the bid, the price moves favourably for whoever
  does the crossing. For example, if the offer is \\$10.01 and someone
  buys out everything that's offered, the price gets higher. The person
  who did the offering has already sold a lot and built up a short position,
  so he needs a greater incentive to sell even more and increase his
  position, and hence his next offer may be \\$10.02. This is why in
  trader jargon buying the offer is called "lifting".
* Other phenomena include: hidden liquidity ("icebergs") and the
  "feeler" trades used to detect it, quoting wars wherein two traders
  will continuously one-up each other until one of them hits their limit,
  and quotes that are very unlikely to be filled. 


# Background on Methodology

So applying a microscope to market dynamics reveals regularities from
which we should be able to determine a fair price. The question is
of course how to achieve this when the dynamics are so ridiculously
complex. 

One answer is to do some feature engineering. When restricted to price
features (not the bid and offer depth), this is the game of technical
analysis, though technical analysis is usually applied to longer timescales.
We can look at features such as the exponential moving average of
the midpoint, the imbalance in the order book, whether it's
the buyers or the sellers that have been crossing the spreads, and
perhaps also the Bollinger Band and the stochastic oscillator. We
could extract all of these features and more for every observation,
use a moving window, and put all of this into your favourite regressor
(if we wanted to predict the next traded price directly) or classifier
(if we wanted a probability distribution on the next traded price). 

What we're doing here is throwing everything at the wall and seeing
what sticks. As we've said, the information to determine a fair price
is in there somewhere, we just don't know how to do it. And a list
of features cannot possibly be exhaustive. It seems like we need some
process to learn how to engineer the features, and of course this
is where neural networks come in. 


## State

One problem with the moving window regime is that our model wouldn't
be able to see any dependency that's longer than the length of the
chosen window. If we take 10 minutes of observations then we can't
see the effect of what happened 11 minutes ago. In financial markets
the dependency can be quite long term, for example if a big buyer
swept the offers in the morning, so that in the afternoon traders
are reluctant to let their offers drop too low in case the big buyer
returns. The next traded price hence depends on the entire history
of trades and orders, but again we don't know how. Our model needs
some way of storing the relevant information about the history of
trades and orders - we need the model to have a "state". 


## Recurrent Neural Networks (RNNs)

The recurrent weights of an RNN constitute a "state", which affects
how it obtains an output from an input. Feeding it data returns an
output, but also changes its state. Hence it's sensitive to the order
in which we feed it inputs, and is ideally suited for sequence data
such as market data. 

The beauty of the RNN is that we have a "distributed representation"
of the state, meaning that it's encoded by the recurrent weights as
opposed to explicitly as in say, a Hidden Markov model. If a HMM has
$N$ different states, then the state itself only contains $\log_{2}N$
bits of information, which really isn't all that much at all. If we
want it to hold 100 bits of information, then we need $2^{100}$ hidden
states, which is just far too many. 

We can also address the long-term dependency problem with architecture
designed specifically for this purpose: the long-short term memory
(LSTM) cell. Here the recurrent weights are protected by a number
of gates that determine whether it gets forgotten or overwritten,
and can hold information for a very long time. The input to the cell
also determines whether its contents are passed on to the rest of
the neural network, which fixes some technical issues with training
neural networks. 


# Model and Data

I found somewhat high frequency market data from [here](http://hopey.netfonds.no/market.php).
It's only the best bid and offer every second or so, so it's a far
cry from actual market data, but it does include every trade, although
it seems like sometimes multiple trades are aggregated. The non-free
alternative is the NYSE OpenBook which may be found [here](http://www.nyxdata.com/Data-Products/NYSE-OpenBook-History). 

I used a total of 34 trading days of data from October 4th to November
18th, 2016. I focused on a single stock, JP Morgan, since it had the
most observations out of stocks in the financial industry. Originally
the plan was to look at orders and trades for other stocks in the
financial industry too, since they are known to be correlated, but
this slowed down training by far too much. 

This data includes trades and orders separately, so I combined both
datasets into a single one where the bids and offers of a trade observation
are carried over from the last known bid and offer, and the trade
volume of an order observation was zero. A big problem was that when
a trade and an order appear with the same timestamp, one can't know
which of the two came first. To simplify things I just got rid of
all orders occurring in the same second as a trade (after carrying
them forward to trade observatoions if applicable). 


## The Data

* Timestamp, bid and offer price and depth, trade quantity and volume. 
* The time since the last observation. This makes the data kind-of like
  a time series, whereas before it wasn't because the time between observations
  isn't constant. 
* A flag for whether the spread is an odd or even number of ticks (ie
  cents). This is because trades can only occur at a whole number of
  cents (unless it occurs at several different prices, in which case
  the trade price is averaged), so the probability distribution of the
  next trade price when the spread is 1 cent looks quite different to
  when it's 2 cents. 
* A flag indicating whether the observation is an order or a trade.
  The model should be able to figure this out for itself but it's spoonfed
  just to be sure. 
* The time until the market opens, for out-of-market-hours observations.
  Most out of market hours observations were dropped to reduce training
  time, but a few were kept to allow the model to prepare itself for
  the chaos of a new trading day. At the end of the day the data was
  padded with copies of the last known observation, so that an input
  batch never contained data from two different days. 

Altogether this constitutes 11 features. 

I also added "dummy observations" that contained no new information.
In such observations the bid and offer price and depth are carried
over from the last known values, and the trade volume is zero. These
were randomly generated at each pass through the training data. 

The model's output is a probability distribution on the price of the
next trade. I had 31 bins where bin number 16 is the midpoint, bin
15 is half a cent below the midpoint and so on. 


## Model Details

The RNN was built using the Python library Keras, with the Theano
backend. I tried several architectures but eventually settled on the
following:


<div class="imgcap">
<img src="/assets/project/2.png">
<div class="thecap" style="text-align:justify">
</div>
</div>


Any larger than this was taking far too long to train. Here the dropout
is 0.2 which I didn't try to optimize, nor did I try to optimize any
of the other hyperparameters such as the unroll length of the RNN
and the batch size. I used a Nadam optimizer (as I'm told it's basically RMSProp with
Nesterov momentum) and of course the categorical cross-entropy loss. 


### Training

Of the 34 days of data, I used the first 29 days (Oct 4th to Nov 11th)
as training data and the last 5 days (Nov 14th to Nov 18th) as test
data. The training history is as shown:

<div class="imgcap">
<img src="/assets/project/3.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Note that I set an epoch to be a whole pass through the training data,
since the loss on any one day had a lot of noise, particularly considering
that Donald Trump was elected towards the end of the training data
period. The model state is reset at the end of the training data so
that it really does start over. By epoch 50 the loss is still decreasing,
but the validation loss is actually slightly increasing. 


## Benchmark

Assessing the model's performance against the inverse weighted midpoint
isn't enough, so I had another model that uses a moving window like
the one that we described previously. Here the window was 6 observations,
for a total of 66 features. I trained four regressors: an Adaboosted
decision tree, a gradient boosted decision tree, a random forest,
and a support vector regressor, with gridsearched hyperparameters
for each. Due to time constraints this benchmark was only trained
on the first week of data from Oct 4th to Oct 8th. The gradient boosted
decision tree performed best, and was used as the benchmark model
in the following section. As a sidenote I should've used XGBoost here,
the speed improvements would probably mean that I could use all the
training data and a much longer window. 


# Results


## Evaluation

To evaluate the RNN, I generated predictions for the test data by
taking the expectation of the outut probability distribution, and
measured the mean squared error between this next traded price and
the prediction. I also measured the correlation coefficient (denoted
$R$) between the difference between the next traded price and the
current midpoint, and the predicted value for this quantity. 

<div class="imgcap">
<img src="/assets/project/4.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

The RNN wins, but the benchmark model is close behind and it's easy
to imagine an ensemble of such models would beat the neural network
if it was trained on the full dataset or used a longer moving window.
The IWM is very far behind as we expect, but it should be noted that
our data issues affected it to a greater extent than the two other
models. Since the order book data for trade observation can be a whole
second old, the IWM can be expected to perform badly when multiple
trades are occurring in the same second. The other two models have
a lot more features to fall back on when the bid and offer become
unreliable. 


### Error Time Series

<div class="imgcap">
<img src="/assets/project/5.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Here we've plotted a time series of $R$ and a moving average of the
mean squared error. The former was obtained by looking at those observations
within the last 30 that represented trades. The time is normalized
so that time 0 is the beginning of the trading day and time 100 is
the end, and the day is the Oct 5th. We can make the following observations:

* We've seen earlier that the RNN wins, but this plot reveals just how
  consistently it wins. With very few exceptions its $R$ is higher
  and its MSE is lower than the other two models. 
* Whenever the MSE spikes, the blue line spikes the highest, and in
  many cases the difference is quite drastic. This is consistent with
  the observation we made earlier about data issues affecting the IWM
  the most. 
* The $R$ value for the IWM spikes downward whenever it spikes upwards
  for the other two models, even becoming negative. Presumably this
  is when a flurry of trades occurs and momentum kicks in, which the
  RNN and benchmark model can make use of, while the IWM is based on
  a more and more outdated order book. 
* Somewhat counterintuitively the $R$ for the red and green lines tends
  to be lower when MSE is low. Perhaps this reflects the fact that in
  low volatility periods the next traded price is actually quite difficult
  to predict, occurring at both the bid and the offer with high probability
  (say 40\%). 

<div class="imgcap">
<img src="/assets/project/6.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

The last of these observations becomes more obvious when we look at
the evaluation metrics over the entire test set, shown above. We have noticeable
spikes in $R$ at the market open when the MSE is highest. 


## Distribution

<div class="imgcap">
<img src="/assets/project/7.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Here's we've plotted a time series of the predictions gainst the target.
The grey shaded region represents the bid and offer depth. What's
interesting is that just by looking at this it's pretty hard to tell
who does better. On one or two occassions here the green line is a
little slow on the uptake, but it doesn't seem all that significant.
Particularly notable is near the end when the IWM predicts a low price
since the bid is thin, and maintains it even when a trade occurs at
the offer. 

This is an example of a low volatility "smooth sailing" situation
where there aren't all that many trades and the price isn't moving
by all that much. The $R$ value is 0.6 for the benchmark and for
the RNN - lower than it is over the entire dataset, while that for
the IWM is higher. This is again consistent with our previous observations. 

<div class="imgcap">
<img src="/assets/project/8.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Here we've created a kind of heatmap where redness indicates the probability
that the next trade will occur at that price. We basically just have
two dark red bands here reflecting the fact that the next trade is
overwhelmingy occurs at the bid or the offer. The band at 67.73 is
also noticeably darker between times 40.3 and 40.6, and stays darker
even while the bid and offer move. 

We've also put the entropy on top of the graph, which roughly speaking
is a measure of how unexpected the trade price was. The redder the
square that a black dot resides on, the lower its entropy. The two
horizontal lines at the top demark an entropy of 1, and if a trade
has entropy 1 then our model was predicting it to happen with $e^{-1}\approx37\%$
probability. An average entropy of 1.3 means that on average the actual
next traded price was assigned a 27\% probability. 


### High Volatility

<div class="imgcap">
<img src="/assets/project/9.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Here I've picked a period where volatility is quite high - you can
see that the red line is jumping around everywhere and the other lines
are having a hard time keeping up. As we've discussed the IWM performs
terribly in this situations and its "predictions" are essentially
random. On the other hand the other two models have high $R$ even
if the MSEs are higher than in the smooth sailing situation. 

<div class="imgcap">
<img src="/assets/project/10.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Now we have bands of red not just at the bid and offer, but also one
cent out from the bid and offer. In the flurry of trades at about
time 7.79, the bands start disintengrating and we just see a mosaic
of red. The entropy of 1.81 translates to the next trade price being
assigned a 16.3\% probability on average. 


## Momentum and Reversion

I'd read somewhere that momentum dominates on short time scales (say
up to a second or two) and reversion dominates on timescales of two
seconds up to say, a minute. To test this hypothesis, for trade observations
I looked at the difference between the trade price and the midpoint
(which we denote with $p$), versus the difference between the next
trade price and the trade price (which we denote $q$). If both $p$
and $q$ are positive, then a trade occurred at higher than the midpoint
and the next trade occurs even higher, indicating a momentum effect.

<div class="imgcap">
<img src="/assets/project/12.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Now $q$ is actually symmetrically distributed, since otherwise we'd
have some kind of chaotic runaway price. But if we look at 30 observation
windows of the correlation between $p$ and $q$, it turns to to be
very negative, with very few occurences of it being positive. This
indicates that reversion dominates, which may be consistent with the
hypothesis given the resolution of our data. However, the model overdoes
this reversion by quite a bit, which indicates that there is still
a lot of room for improvement. 


## Backtesting

The most obvious way to use the model as a trading strategy is to
buy whenever the offer is lower than the fair price, and sell whenever
the bid is higher than the fair price. But doing this directly runs
into several problems due to the quality of the quote data - in many
cases we'd be trying to hit quotes that are a second old. Furthermore
since it's probably only under volatile circumstances where the model
predicts that crossing the spread would be profitable, and it's precisely
here that being able to hit the second-old quote is highly unlikely. 

Nevertheless what we _can_ do is pit the models against each
other two at a time in the following manner:

* At each trade observation, the model that values it higher buys it
  off the model that values it lower. The trade price is the midpoint
  between the model's two prices. 
* They each get out of the position at the next traded price, and their
  profit or loss is added to their account. 

Of course, at the end we can look at what each model has in their
account to determine the winner. 


### Backtesting Results

<div class="imgcap">
<img src="/assets/project/13.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Here we've plotted how much money the RNN has against the IWM and
the benchmark, and as expected, it wins. We make the following observations:

* Most gains occur on the market open and the market close. The profit
  decelerates as the day goes on. 
* What's remarkable is just how consistently it wins - at this scale
  the curve almost looks smooth. 

<div class="imgcap">
<img src="/assets/project/14.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Zooming in to a single day we see that it isn't quite smooth - there
are kinks, and here the RNN even loses money against the benchmark
for an extended period of time. I haven't looked into this yet but
it will no doubt expose another shortcoming of the model. 

The red dotted line is the predicted volatility, that is the standard
devivation of the predicted probability distribution. Two salient
features of this graph are highlighted with boxes - Firstly there
is a very slight dip in the blue line, and in the other box there
is a sudden jump that coincides with a spike in predicted volatility. 

<div class="imgcap">
<img src="/assets/project/15.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Zooming in on the first box reveals a period of very low volatility,
whence it's immediately clear why the RNN loses money - given that
the next traded price occurs at either the bid or the offer, the IWM
is presumably quite accurate, and when this occurs over a long period
of time, the IWN wins, since its price isn't skewed by the possibility
of jumps. But when the jumps occur, it loses what it gained almost
at once. Note that on this scale the blue line of instantaneous PnL
appears to be random. 

<div class="imgcap">
<img src="/assets/project/16.png">
<div class="thecap" style="text-align:justify">
</div>
</div>

Zooming in on the second box reveals a flurry of trades - of course!
Here the price seems to be moving in one direction until it realizes
that it's gone too far and reverts a little. As discussed in these
situations the last known bid and offer are not good predictors of
the next traded price at all. 


# Future Development


## Improvements

* Of course the data is really pretty poor compared to actual market
  data. Not just in time resolution, but we could also use the full
  order book, and data from other markets as originally planned. 
* The model can be much larger - 3 hidden layers doesn't even really
  qualify as deep learning. 
* The hyperparameters can be optimized, perhaps with the hyperas library.
  This wasn't pursued at all in this project beyond some initial trial
  and error. 
* The training procedure can be improved. We can randomly reset the
  network's state and start over from a random day. 
* The architecture can be improved. Keras only really facilitates a
  layer-by-layer architecture, while cutting edge neural networks are
  utilizing exotic components such as memory stacks. 
* In terms of raw performance, the history of Kaggle winners has shown
  that an ensemble of many different models usually wins out. Here we
  can combine something like an XGBoosted model to handle short term
  dynamics while the RNN handles long term dependencies. 


## Applications

In practice, using the model to generate predictions as market data
comes pouring in has several technical issues. My computer takes about
a minute to generate the predictions for a day of predictions consisting
of about 40000 observations. Naively taking the ratio yields 1.5 milliseconds
for a single observation, which is one the slow side for high frequency
trading. No doubt this can be improved with better hardware, but the
model will surely be more complex too. 

Nevertheless what we definitely can do is use this framework as a
generative model for market dynamics. We've predicted a probability
distribution for the next traded price; we need the volume and time
of the next traded price too. And we need to do it for orders, not
just for trades. The volume can be predicted using the price as an
input, and the time can be predicted using both price and volume as
inputs. Once we have all of this then we have a joint distribution
for the next trade price, volume, and time, and hence a complete model
of market dynamics.

From here the most immediate application would be in generating data
to backtest strategies. A well known problem in backtesting is not
knowing whether a trading strategy's performance depends on historical
idiosyncracies, and using such a model would partially alleviate such
concerns (albeit introduce a few of its own). 


### Making Money

The ultimate goal is to use knowledge of market dynamics to conceive
of a trading strategy - but that is another topic entirely. Theoretically
one can come up with an _optimal_ trading strategy, in the one
asset case using the theory of optimal stopping, and in the general
case the theory of stochastic control. 
