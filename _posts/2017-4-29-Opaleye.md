---
layout: post
title: Composability in SQL
---

Making complex querying a lot easier. 

So in this new job, I had to write a lot of SQL, and of course after a while it gets frustrating having to write it from scratch every time. so you put together a few python scripts that take a few bits of strings each time and stitch them together into the query that you want. So for particular derived properties that you need from other tables, you say what tables you need to join on and how you join, then add this to the main query.

After you do this for a while it just gets really hard to maintain and reason about. It's hard to keep track of which bits of the query come from where, you run into conflicts with naming your tables, you have all of these `{joiners}` bits in your query strings that you have to do some detective work to find out when it gets injected. 

And it just doesn't have to be this way. SQL is really just a terrible language: reasoning about it is very hard, the meaning of the query is spread out throughout the whole query, you can't break it up into little parts that fit together into a whole. On the other hand, pure relational algebra is both easy to read and quite composable. Why don't we have it like this? Well, we can, and this is what this post will get at. 

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


## A Motivating Example

I'm going to use an example directly from my work. Suppose we have a website where users create projects for freelancers to do. The freelancer bids on the projects, gets chosen by the employer, does the work, and then gets paid. Of course, sometimes this doesn't happen - either the freelancer doesn't do the work, or doesn't get paid. 

So we have a table of users (*dim_user*), a table of projects (*dim_project*), and a table of payments (*fact_milestone*). Each project has a user that created the project. Each payment has an associated project, and a user who made the payment. Users also may or may not be a bot. 

Now suppose we want to look at whether a particular user retains. Which means, that they created a project, made a payment on that project, then came back and made another project within 3 months. In SQL this query is already pretty big. 

The first thing we need is to get, for each user, the first time that that user made a payment. This is the query below:

```sql
SELECT * from
  (SELECT t1.user_id, min(t1.transaction_timestamp) transaction_timestamp
  FROM fact_milestone t1
  GROUP BY user_id) as t1,
  fact_milestone as t2
where t1.user_id = t2.user_id and t1.transaction_timestamp = t2.transaction_timestamp
```

Now for each user, we need to look at whether he or she submitted any projects within 3 months of this, so we need:

```sql
select distinct t1.user_id, case when p.user_id is not null then true else false end is_retained
from
	{above} as t1
	left join dim_project p on p.submit_timestamp between t1.transaction_timestamp and t1.transaction_timestamp + interval '3 month'

```



### Conceptually, what is this?

In SQLalchemy, something like `user.payments.min(key=timestamp).afterprojects.exists()` where afterprojects has another definition. Problem is that it only does this for one user, and if you do it for other uers it does the one user thing one by one. 



### Opaleye

But in Opaleye, check this out:

```haskell
uid_retained :: Int -> Query (Col Int) -> Query (Col Int, Col Bool)
uid_retained time q = 
  q >>> joinOn Mst.query Mst.user_id 
    >.> minBy Mst.user_id Mst.transaction_timestamp
    >>> returnA &&& (ljoinA Proj.query cond)
    >>> arr Mst.user_id *** liftA3 ifThenElse (arr $ isNull . Proj.project_id) (pure.constant $ False) (pure.constant $ True)
    >.> distinct
      where 
        cond (m, p) = epoch(Proj.submit_timestamp p) .> epoch(Mst.transaction_timestamp m)
          .&& epoch(Proj.submit_timestamp p) .< epoch(Mst.transaction_timestamp m) + constant time
          .&& Proj.user_id p .== Mst.user_id m
```

In words: for a given user, 

* look at all of their payments.
* take the first one.
* now look at all of their projects that came after that payment date. 
* return the user, and whether a project exists
* now take the distinct ones

Much more intuitive. 

## Arrows

Thing is, once we know how to do it for a single user, Opaleye has the internals to figure out how to do it for all users. This really is like binding a function `a -> [b]` to a list `[a]`. Difference is that We have an arrow, not a monad, and for a very good reason. 

Suppose we had something like

```haskell
aggregateArrow = proc (u0) -> do
	m0 <- getpayments -< u0
	count0 <- aggregate count -< m0
	restrict -< projectpayments m0 .== count0
	returnA -< count0
```

What does this even mean anymore? We're getting the count of payments for a user, but only if the count matches the number of payments that the project associated with that payment received? But we're only returning the count anyway! Or the count of (payments by a user on projects whose associated number of payments is the same as the total number of payments by that user)? It's just incoherent now.  

It's like when whenever aggregate, using results that came from before just doesn't make sense anymore. We shouldn't be able to use `m0` at all after we aggregate. We effectively "destroy" it.

When we draw out the arrow as a circuit of computations, it's like for an aggregate arrow, we can draw a box around the input and output so that nothing leaves that box except via the aggregate arrow itself. Need a diagram for this. 

And that's why we can't have aggregate as a `QueryArr (a) (b)`, only as a `Query (a) -> Query (b)`. It just becomes a little harder to compose. 

### Composition

I'm really getting the hang of this now. Think of an arrow `Arrow a b`  as a function `a -> b`, and a term as an arrow `Arrow () b` . The difference is that when you join arrows together, you don't know what the input is going to be, you can't choose what arrows you use based on the inputs that you get. Unless of course the arrow itself has a special way to know the input, in which case you've got an `ArrowApply` which is just a monad. Note that you *can* feed output from arrows into other arrows which is what makes it more powerful than applicative functors. But this is the only thing you can do. 

In do notation, while for monads you can have any arbitrary `a -> m b` , for arrows you're allow to get that `m b` via an arrow. For monads you can write:

```haskell
go x = do
	a <- f x
	b <- g x a
	c <- h x a b
	return c
```

With arrows you can replicate this behaviour with

```haskell
go = proc x -> do
	a <- f -< x
	b <- g -< (x, a)
	c <- h -< (x, a, b)
	returnA -< c
```

Actually of course whatever you have can be done with monads and that'll be easier on the part of the programmer, it's that arrows will make it harder to do the wrong thing, and will also make things much easier for the computer. 

Remember that the advantage the applicative parser has over the monadic one is just that it uses much less memory. 